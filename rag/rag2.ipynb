{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073fb877-476c-4156-a105-52235f38f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL = 'llama3.2:1b'\n",
    "EMBED_MODEL = 'BAAI/bge-large-en-v1.5'\n",
    "RERANK_MODEL = 'BAAI/bge-reranker-base'\n",
    "INPUT_DIR_PATH = './paul_graham'\n",
    "COLLECTION_NAME = \"document_chat\"\n",
    "EVAL_GENERATOR_MODEL = 'phi3:3.8b'\n",
    "EVAL_EMBED_MODEL = 'nomic-embed-text'\n",
    "EVAL_CRITIC_MODEL = 'llama3.2:1b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996ecf28-57de-449c-bacc-59114a14104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ffd80fb-8cc6-4eea-b719-da6638e1767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "llm = Ollama(model=LLM_MODEL, temperature=0, request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "233893f9-319c-4b62-83e1-a844e9140dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "embed_model = FastEmbedEmbedding(model_name=EMBED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f029cd34-ddb1-4db0-95eb-79e6c1a4cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "reranker = SentenceTransformerRerank(model=RERANK_MODEL, top_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3533067-2a3a-4721-9275-dcbd2957e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "db_client = QdrantClient(host='localhost', port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "717d9a96-b3d4-4eb4-a1c3-0bc51bdddf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4f96abd-436b-4b13-bde1-43f923b6e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "loader = SimpleDirectoryReader(\n",
    "    input_dir= INPUT_DIR_PATH,\n",
    "    required_exts=['.txt'],\n",
    "    recursive=True)\n",
    "docs = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6be4d27-c2b1-4295-8d19-c0763695a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "\n",
    "vector_store = QdrantVectorStore(client= db_client, collection_name= COLLECTION_NAME)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(documents=docs, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e7a96cd-bce5-4385-94dd-61aab436585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "    Context information is below.\n",
    "    -------------------------\n",
    "    {context_str}\n",
    "    -------------------------\n",
    "    Given the context information above, i want you to think\n",
    "    step by step to answer the query in a crisp manner. Incase\n",
    "    you don't know the answer, say 'I don't know'.\n",
    "\n",
    "    Query: {query_str}\n",
    "\n",
    "    Answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top = 4, node_postprocessors=[reranker])\n",
    "query_engine.update_prompts(\n",
    "    {'response_synthesizer:text_qa_template': qa_template}\n",
    ")\n",
    "query = \"\"\"How did the structure of funding startups in batches contribute \n",
    "        to the growth and success of the Y Combinator program and the\n",
    "        startups involved?\"\"\"\n",
    "response = query_engine.query(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "823d5224-d527-4b72-bbd0-e73bda91fe2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To address your query, let's break down the steps that contributed to the growth and success of the Y Combinator (YC) program and the startups involved:\n",
       "\n",
       "1. **Batch Funding**: The founders of YC started funding startups in batches, which allowed them to do things for a large number of startups at once but also provided a more convenient way for founders to receive funding.\n",
       "\n",
       "2. **Convenience and Scalability**: By doing funding in batches, YC could scale its operations efficiently, allowing it to handle a larger number of startups simultaneously. This facilitated the process of finding suitable startups and providing them with necessary resources.\n",
       "\n",
       "3. **Isolation and Community Building**: The batch funding model helped create an environment where founders felt more connected to each other. They shared experiences, advice, and support, which fostered a sense of community among the YC alumni. This community became crucial for helping one another in their entrepreneurial journeys.\n",
       "\n",
       "4. **Founders' Network**: As the number of startups grew, so did the size of the network within YC. The batch funding model enabled founders to connect with each other and gain access to resources, mentorship, and potential investors. This network played a significant role in helping founders navigate the challenges of starting and growing their businesses.\n",
       "\n",
       "5. **Customer Acquisition**: By providing initial customers to many startups through their batch funding, YC helped accelerate the growth of its alumni companies. This not only benefited the founders but also contributed to the overall success of the Y Combinator program.\n",
       "\n",
       "6. **Mentorship and Support**: The batch funding model allowed for a more efficient allocation of resources within YC. Founders could receive guidance from experienced mentors, which helped them overcome obstacles and achieve their goals.\n",
       "\n",
       "7. **Feedback Loop**: As founders received funding from multiple batches, they were able to test and refine their ideas through experimentation with different approaches. This feedback loop enabled the Y Combinator program to continuously improve its selection process and provide better support for its entrepreneurs.\n",
       "\n",
       "In summary, the structure of funding startups in batches was a key factor in the growth and success of the Y Combinator program and the startups involved. It facilitated scalability, community building, customer acquisition, mentorship, and a feedback loop that helped entrepreneurs refine their ideas and achieve success."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(str(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04bf00-a032-4654-a2b9-b4adf5a03e73",
   "metadata": {},
   "source": [
    "# EVALUATION / TESTING USING Raagas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea5a5369-e660-4c61-9766-0833e9c932c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ollama\n",
    "DEFAULT_REQUEST_TIMEOUT = 120.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a49ed9cc-60c1-466b-a520-baade43ef3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = DirectoryLoader('./paul_graham/')\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "documents = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d97eda4-27eb-4a31-accc-0567855efbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'schema', 'document', 'Document'],\n",
       " 'kwargs': {'metadata': {'source': 'paul_graham/how_to_do_great_things.txt'},\n",
       "  'page_content': 'How to Do Great Work\\n\\nJuly 2023\\n\\nIf you collected lists of techniques for doing great work in a lot of different fields, what would the intersection look like? I decided to find out by making it.\\n\\nPartly my goal was to create a guide that could be used by someone working in any field. But I was also curious about the shape of the intersection. And one thing this exercise shows is that it does have a definite shape; it\\'s not just a point labelled \"work hard.\"\\n\\nThe following recipe assumes you\\'re very ambitious.\\n\\nThe first step is to decide what to work on. The work you choose needs to have three qualities: it has to be something you have a natural aptitude for, that you have a deep interest in, and that offers scope to do great work.\\n\\nIn practice you don\\'t have to worry much about the third criterion. Ambitious people are if anything already too conservative about it. So all you need to do is find something you have an aptitude for and great interest in. [1]',\n",
       "  'type': 'Document'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81c60594-e622-49c2-ac4c-c75f3f063f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "generator_llm = OllamaLLM(model = EVAL_CRITIC_MODEL)\n",
    "# critic_llm = Ollama(model= EVAL_CRITIC_MODEL)\n",
    "embedding_model = OllamaEmbeddings(model = EVAL_EMBED_MODEL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b7c80-3ed0-44c4-a8c1-4e051eb37107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    llm= generator_llm,\n",
    "    embedding_model= embedding_model\n",
    ")\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents=documents,\n",
    "    testset_size=10,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "   \n",
    "# distribution = { simple: 0.5, reasoning: 0.25, multi_context: 0.25}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caf48870-9e3a-4303-9977-aa86142d889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv('./test/test_data_paul_graham.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ffab40f-6adc-4da0-b22a-78658543260b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How did the shift to publishing on the web cha...</td>\n",
       "      <td>[\"Wow, I thought, there's an audience. If I wr...</td>\n",
       "      <td>The shift to publishing on the web changed the...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>How does criticizing a project as a \"toy\" rese...</td>\n",
       "      <td>[\"[9] You can't usually get paid for doing exa...</td>\n",
       "      <td>Criticizing a project as a 'toy' is similar to...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How did the structure of funding startups in b...</td>\n",
       "      <td>['The deal for startups was based on a combina...</td>\n",
       "      <td>Funding startups in batches allowed for conven...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>How can exploring different topics help in gen...</td>\n",
       "      <td>[\"Talking or writing about the things you're i...</td>\n",
       "      <td>Exploring different topics can help in generat...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How does focusing consistently on something yo...</td>\n",
       "      <td>[\"The way to beat it is to stop occasionally a...</td>\n",
       "      <td>Great work happens by focusing consistently on...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0  How did the shift to publishing on the web cha...   \n",
       "1           1  How does criticizing a project as a \"toy\" rese...   \n",
       "2           2  How did the structure of funding startups in b...   \n",
       "3           3  How can exploring different topics help in gen...   \n",
       "4           4  How does focusing consistently on something yo...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [\"Wow, I thought, there's an audience. If I wr...   \n",
       "1  [\"[9] You can't usually get paid for doing exa...   \n",
       "2  ['The deal for startups was based on a combina...   \n",
       "3  [\"Talking or writing about the things you're i...   \n",
       "4  [\"The way to beat it is to stop occasionally a...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  The shift to publishing on the web changed the...         simple   \n",
       "1  Criticizing a project as a 'toy' is similar to...         simple   \n",
       "2  Funding startups in batches allowed for conven...         simple   \n",
       "3  Exploring different topics can help in generat...         simple   \n",
       "4  Great work happens by focusing consistently on...         simple   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "1  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "2  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "3  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "4  [{'source': 'paul_graham/how_to_do_great_thing...          True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f8bc51c-c46e-4ddd-a58a-e21be97f1c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query_engine, question):\n",
    "    response = query_engine.query(question)\n",
    "    return {\n",
    "        \"answer\": response.response,\n",
    "        \"contexts\": [c.node.get_content() for c in response.source_nodes],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e334187-9b8e-47e8-a215-8b6ab8c79a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d94b169bf174f1ebed43dfa90248b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "test_questions = test_df['question'].values\n",
    "\n",
    "responses = [generate_response(query_engine, q) for q in tqdm(test_questions)]\n",
    "dataset_dict = {\n",
    "    \"question\": test_questions, \n",
    "    \"answer\": [response[\"answer\"] for response in responses],\n",
    "    \"contexts\": [response[\"contexts\"] for response in responses],\n",
    "    \"ground_truth\": test_df[\"ground_truth\"].values.tolist(),\n",
    "    \n",
    "}\n",
    "ragas_eval_dataaset = Dataset.from_dict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30ddc8ec-b6ce-4147-9143-3b9590003de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How did the shift to publishing on the web change the availability of an audience for writers?',\n",
       " 'answer': \"Based on the context information provided, it appears that the shift to publishing online changed the availability of an audience for writers in several ways:\\n\\n1. **Increased accessibility**: With the advent of the internet, more people had access to writing and publishing opportunities, making it easier for writers to share their work with a wider audience.\\n\\n2. **Democratization of publishing**: The web enabled writers to self-publish their work without needing traditional gatekeepers like publishers or agents. This democratization of publishing allowed more voices to be heard and gave writers greater control over the dissemination of their content.\\n\\n3. **Shift from print to online presence**: As writing became more accessible, the need for a physical print platform (like newspapers) decreased, allowing writers to focus on creating digital content that could reach a broader audience.\\n\\n4. **New channels for discovery**: The web provided new platforms for readers to discover and engage with writers' work, such as blogs, online forums, and social media. This increased visibility helped writers build their personal brands and connect with potential readers.\\n\\n5. **Changes in reader behavior**: With the rise of online publishing, readers' expectations and behaviors changed. They began to expect more frequent updates from writers, which led to a shift away from traditional publishing schedules and towards more dynamic, ongoing writing projects.\\n\\n6. **Increased competition for attention**: The web also created new challenges for writers, as they faced increased competition for attention from a larger pool of readers. This required them to be more creative, engaging, and effective in their online presence.\\n\\nOverall, the shift to publishing on the web has transformed the way writers reach an audience, making it easier for them to share their work with a broader audience, but also presenting new challenges and opportunities for writers to succeed.\",\n",
       " 'contexts': ['[7] Technically the apartment wasn\\'t rent-controlled but rent-stabilized, but this is a refinement only New Yorkers would know or care about. The point is that it was really cheap, less than half market price.\\n\\n[8] Most software you can launch as soon as it\\'s done. But when the software is an online store builder and you\\'re hosting the stores, if you don\\'t have any users yet, that fact will be painfully obvious. So before we could launch publicly we had to launch privately, in the sense of recruiting an initial set of users and making sure they had decent-looking stores.\\n\\n[9] We\\'d had a code editor in Viaweb for users to define their own page styles. They didn\\'t know it, but they were editing Lisp expressions underneath. But this wasn\\'t an app editor, because the code ran when the merchants\\' sites were generated, not when shoppers visited them.\\n\\n[10] This was the first instance of what is now a familiar experience, and so was what happened next, when I read the comments and found they were full of angry people. How could I claim that Lisp was better than other languages? Weren\\'t they all Turing complete? People who see the responses to essays I write sometimes tell me how sorry they feel for me, but I\\'m not exaggerating when I reply that it has always been like this, since the very beginning. It comes with the territory. An essay must tell readers things they don\\'t already know, and some people dislike being told such things.\\n\\n[11] People put plenty of stuff on the internet in the 90s of course, but putting something online is not the same as publishing it online. Publishing online means you treat the online version as the (or at least a) primary version.\\n\\n[12] There is a general lesson here that our experience with Y Combinator also teaches: Customs continue to constrain you long after the restrictions that caused them have disappeared. Customary VC practice had once, like the customs about publishing essays, been based on real constraints. Startups had once been much more expensive to start, and proportionally rare. Now they could be cheap and common, but the VCs\\' customs still reflected the old world, just as customs about writing essays still reflected the constraints of the print era.\\n\\nWhich in turn implies that people who are independent-minded (i.e. less influenced by custom) will have an advantage in fields affected by rapid change (where customs are more likely to be obsolete).\\n\\nHere\\'s an interesting point, though: you can\\'t always predict which fields will be affected by rapid change. Obviously software and venture capital will be, but who would have predicted that essay writing would be?\\n\\n[13] Y Combinator was not the original name. At first we were called Cambridge Seed. But we didn\\'t want a regional name, in case someone copied us in Silicon Valley, so we renamed ourselves after one of the coolest tricks in the lambda calculus, the Y combinator.\\n\\nI picked orange as our color partly because it\\'s the warmest, and partly because no VC used it. In 2005 all the VCs used staid colors like maroon, navy blue, and forest green, because they were trying to appeal to LPs, not founders. The YC logo itself is an inside joke: the Viaweb logo had been a white V on a red circle, so I made the YC logo a white Y on an orange square.\\n\\n[14] YC did become a fund for a couple years starting in 2009, because it was getting so big I could no longer afford to fund it personally. But after Heroku got bought we had enough money to go back to being self-funded.\\n\\n[15] I\\'ve never liked the term \"deal flow,\" because it implies that the number of new startups at any given time is fixed. This is not only false, but it\\'s the purpose of YC to falsify it, by causing startups to be founded that would not otherwise have existed.\\n\\n[16] She reports that they were all different shapes and sizes, because there was a run on air conditioners and she had to get whatever she could, but that they were all heavier than she could carry now.\\n\\n[17] Another problem with HN was a bizarre edge case that occurs when you both write essays and run a forum. When you run a forum, you\\'re assumed to see if not every conversation, at least every conversation involving you. And when you write essays, people post highly imaginative misinterpretations of them on forums. Individually these two phenomena are tedious but bearable, but the combination is disastrous.'],\n",
       " 'ground_truth': 'The shift to publishing on the web changed the availability of an audience for writers by removing the need to go through traditional channels like books, newspapers, or magazines. Previously, writers had to get their work published through these limited mediums to reach an audience, but with the web, anyone could publish anything and potentially reach a wide audience.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_eval_dataaset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a0d4f22-84f9-4c4a-b5ef-5531f7c7d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "from ragas import evaluate, RunConfig\n",
    "from ragas.metrics import (faithfulness, answer_correctness, \n",
    "    context_recall, context_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1658cb9-fa41-4c51-b766-fdadf2fae82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37ddc9c969549b6ab248e6a2ee1dfbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[17]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[33]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[52]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[53]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[56]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[65]: TimeoutError()\n",
      "Exception raised in Job[69]: TimeoutError()\n",
      "Exception raised in Job[72]: TimeoutError()\n",
      "Exception raised in Job[73]: TimeoutError()\n",
      "Exception raised in Job[76]: TimeoutError()\n",
      "Exception raised in Job[77]: TimeoutError()\n",
      "Exception raised in Job[81]: TimeoutError()\n",
      "Exception raised in Job[85]: TimeoutError()\n",
      "Exception raised in Job[88]: TimeoutError()\n",
      "Exception raised in Job[89]: TimeoutError()\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[93]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[92]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[96]: TimeoutError()\n",
      "Exception raised in Job[97]: TimeoutError()\n",
      "Exception raised in Job[100]: TimeoutError()\n",
      "Exception raised in Job[101]: TimeoutError()\n",
      "Exception raised in Job[102]: TimeoutError()\n",
      "Exception raised in Job[103]: TimeoutError()\n",
      "Exception raised in Job[104]: TimeoutError()\n",
      "Exception raised in Job[105]: TimeoutError()\n",
      "Exception raised in Job[113]: TimeoutError()\n",
      "Exception raised in Job[114]: TimeoutError()\n",
      "Exception raised in Job[118]: TimeoutError()\n",
      "Exception raised in Job[120]: TimeoutError()\n",
      "Exception raised in Job[121]: TimeoutError()\n",
      "Exception raised in Job[125]: TimeoutError()\n",
      "Exception raised in Job[128]: TimeoutError()\n",
      "Exception raised in Job[129]: TimeoutError()\n",
      "Exception raised in Job[132]: TimeoutError()\n",
      "Exception raised in Job[133]: TimeoutError()\n",
      "Exception raised in Job[134]: TimeoutError()\n",
      "Exception raised in Job[135]: TimeoutError()\n",
      "Exception raised in Job[137]: TimeoutError()\n",
      "Exception raised in Job[138]: TimeoutError()\n",
      "Exception raised in Job[141]: TimeoutError()\n",
      "Exception raised in Job[144]: TimeoutError()\n",
      "Exception raised in Job[145]: TimeoutError()\n",
      "Exception raised in Job[149]: TimeoutError()\n",
      "Exception raised in Job[152]: TimeoutError()\n",
      "Exception raised in Job[153]: TimeoutError()\n",
      "Exception raised in Job[155]: TimeoutError()\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[157]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[156]: TimeoutError()\n",
      "Exception raised in Job[160]: TimeoutError()\n",
      "Exception raised in Job[161]: TimeoutError()\n",
      "Exception raised in Job[162]: TimeoutError()\n",
      "Exception raised in Job[164]: TimeoutError()\n",
      "Exception raised in Job[165]: TimeoutError()\n",
      "Exception raised in Job[168]: TimeoutError()\n",
      "Exception raised in Job[169]: TimeoutError()\n",
      "Exception raised in Job[170]: TimeoutError()\n",
      "Exception raised in Job[173]: TimeoutError()\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt statement_generator_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[177]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[176]: TimeoutError()\n",
      "Exception raised in Job[181]: TimeoutError()\n"
     ]
    }
   ],
   "source": [
    "metrics = [faithfulness, answer_correctness, context_recall, context_precision]\n",
    "run_config = RunConfig(timeout=120)\n",
    "\n",
    "\n",
    "critic_llm = OllamaLLM(model = EVAL_CRITIC_MODEL, format='json')\n",
    "embed_llm = OllamaEmbeddings(model = EVAL_EMBED_MODEL)\n",
    "\n",
    "evaluation_result = evaluate(\n",
    "    llm= critic_llm,\n",
    "    embeddings= embed_llm, \n",
    "    dataset= ragas_eval_dataaset,\n",
    "    metrics= metrics,\n",
    "    run_config= run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5a9f023-6763-4ac2-ac6e-45fac0880053",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_scores_df = pd.DataFrame(evaluation_result.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cb8c9d9-b85e-4c05-a0e2-e9d4908d4071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   faithfulness  answer_correctness  context_recall  context_precision\n",
       "0           NaN                 NaN             0.5                1.0\n",
       "1           NaN                 NaN             1.0                1.0\n",
       "2           NaN                 NaN             0.8                1.0\n",
       "3          0.25                 NaN             0.5                1.0\n",
       "4           NaN                 NaN             1.0                1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48beb6f-aa9a-40bc-874b-676499d8a897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
